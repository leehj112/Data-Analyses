{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMY9ntk1dJ0p+8nwT5TAzT9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leehj112/Data-Analyses/blob/master/colab_pooling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK7-qiJwVDqx",
        "outputId": "92f7e1a6-96a0-45f7-ff7c-7b9f9cbbd8e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input :  tf.Tensor(\n",
            "[[[ 1.  3.]\n",
            "  [ 5.  7.]\n",
            "  [ 9.  2.]\n",
            "  [ 4.  6.]\n",
            "  [ 8. 10.]]], shape=(1, 5, 2), dtype=float32)\n",
            "\n",
            "max pooling 1d :  tf.Tensor(\n",
            "[[[ 5.  7.]\n",
            "  [ 9.  7.]\n",
            "  [ 9.  6.]\n",
            "  [ 8. 10.]]], shape=(1, 4, 2), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x = tf.constant([1., 3., 5., 7., 9., 2., 4., 6., 8., 10.])\n",
        "x1 = tf.reshape(x, [1, 5, 2])\n",
        "maxpool1d = tf.keras.layers.MaxPooling1D(pool_size=2, strides=1,\n",
        "                                         padding='valid')(x1)\n",
        "\n",
        "print(\"input : \", x1)\n",
        "print(\"\\nmax pooling 1d : \" ,maxpool1d)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x2 = tf.reshape(x, [1, 2, 5])\n",
        "averagepool1d = tf.keras.layers.AveragePooling1D(pool_size=2, strides=1,\n",
        "                                             padding='same')(x2)\n",
        "print(\"input : \", x2)\n",
        "print(\"\\nAverage pooling 1d : \" ,averagepool1d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNG7YgT2VHvD",
        "outputId": "4fdab37c-223e-452d-a15d-f6bec0eaea1a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input :  tf.Tensor(\n",
            "[[[ 1.  3.  5.  7.  9.]\n",
            "  [ 2.  4.  6.  8. 10.]]], shape=(1, 2, 5), dtype=float32)\n",
            "\n",
            "Average pooling 1d :  tf.Tensor(\n",
            "[[[ 1.5  3.5  5.5  7.5  9.5]\n",
            "  [ 2.   4.   6.   8.  10. ]]], shape=(1, 2, 5), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "globalmaxpool1d = tf.keras.layers.GlobalMaxPooling1D()(x2)\n",
        "globalaveragepool1d = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
        "\n",
        "print(\"Global max pooling 1d : \" ,globalmaxpool1d)\n",
        "print(\"\\nGlobal average pooling 1d : \" ,globalaveragepool1d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sYOgqv9VJbl",
        "outputId": "d98c54b9-0a3e-489d-9c34-e0f306683203"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global max pooling 1d :  tf.Tensor([[ 2.  4.  6.  8. 10.]], shape=(1, 5), dtype=float32)\n",
            "\n",
            "Global average pooling 1d :  tf.Tensor([[1.5 3.5 5.5 7.5 9.5]], shape=(1, 5), dtype=float32)\n"
          ]
        }
      ]
    }
  ]
}